{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cac41d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e0e7dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>348103</td>\n",
       "      <td>If you don't like rock then your not going to ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232070</th>\n",
       "      <td>348106</td>\n",
       "      <td>You how you can tell i have so many friends an...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232071</th>\n",
       "      <td>348107</td>\n",
       "      <td>pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232072</th>\n",
       "      <td>348108</td>\n",
       "      <td>The usual stuff you find hereI'm not posting t...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232073</th>\n",
       "      <td>348110</td>\n",
       "      <td>I still haven't beaten the first boss in Hollo...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232074 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                2  Ex Wife Threatening SuicideRecently I left my ...   \n",
       "1                3  Am I weird I don't get affected by compliments...   \n",
       "2                4  Finally 2020 is almost over... So I can never ...   \n",
       "3                8          i need helpjust help me im crying so hard   \n",
       "4                9  I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...   \n",
       "...            ...                                                ...   \n",
       "232069      348103  If you don't like rock then your not going to ...   \n",
       "232070      348106  You how you can tell i have so many friends an...   \n",
       "232071      348107  pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...   \n",
       "232072      348108  The usual stuff you find hereI'm not posting t...   \n",
       "232073      348110  I still haven't beaten the first boss in Hollo...   \n",
       "\n",
       "              class  \n",
       "0           suicide  \n",
       "1       non-suicide  \n",
       "2       non-suicide  \n",
       "3           suicide  \n",
       "4           suicide  \n",
       "...             ...  \n",
       "232069  non-suicide  \n",
       "232070  non-suicide  \n",
       "232071  non-suicide  \n",
       "232072      suicide  \n",
       "232073  non-suicide  \n",
       "\n",
       "[232074 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression = pd.read_csv ('Suicide_Detection.csv')\n",
    "depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac97cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "depression['class'] = depression['class'].map({'suicide': 1, 'non-suicide': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc4e4927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  Ex Wife Threatening SuicideRecently I left my ...      1\n",
       "1  Am I weird I don't get affected by compliments...      0\n",
       "2  Finally 2020 is almost over... So I can never ...      0\n",
       "3          i need helpjust help me im crying so hard      1\n",
       "4  I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...      1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression = depression[['text','class']]\n",
    "depression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f72d570c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/deni.emmer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/deni.emmer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/deni.emmer/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/deni.emmer/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a352c33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116037, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep = depression[depression['class'] == 1]\n",
    "dep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e424823f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116037, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndep = depression[depression['class'] == 0]\n",
    "ndep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4335bb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/8c6p2kfn5z98lys6tff8f9jm0000gn/T/ipykernel_42446/2555803311.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dep['length'] = list(map(lambda x: len(str(x).split()), dep['text']))\n"
     ]
    }
   ],
   "source": [
    "dep['length'] = list(map(lambda x: len(str(x).split()), dep['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "11f93c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65179, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep = dep[dep['length'] < 150]\n",
    "dep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8fbabe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/8c6p2kfn5z98lys6tff8f9jm0000gn/T/ipykernel_42446/2399448930.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ndep['length'] = list(map(lambda x: len(str(x).split()), ndep['text']))\n"
     ]
    }
   ],
   "source": [
    "ndep['length'] = list(map(lambda x: len(str(x).split()), ndep['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce1cc2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65179, 3)\n",
      "(64999, 3)\n"
     ]
    }
   ],
   "source": [
    "ndep = ndep[ndep['length'] < 36]\n",
    "print (dep.shape)\n",
    "print (ndep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eeb28a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "condata = pd.concat([dep, ndep], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c91621e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = condata.sample(frac=0.54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a359650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = ['']\n",
    "corpus=[]\n",
    "for post in data['text']:\n",
    "    posts.append(post)\n",
    "    corpus.append(nltk.sent_tokenize(post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cedd00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## flatten the list\n",
    "corpus=[sent for sublist in corpus for sent in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "42388a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_post(x):\n",
    "    x = str(x).lower().replace(\"\\\\\",\"\").replace(\"_\",\" \")\n",
    "    x = re.sub(r'\\W+',' ',x) # Replace everything non-alpahnumeric by ' '\n",
    "    x = re.sub(r'\\s+',' ',x) # Replace one or more whitespaces by  ' '\n",
    "    x = re.sub(r'\\d+',' ',x) # Replace one or more digits by  ' '\n",
    "    x = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\" \", x) # Replace e-mails by ''\n",
    "    # Replace urls by ''\n",
    "    x = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', ' ' , x) \n",
    "    # Replace html tags by ''\n",
    "    x = BeautifulSoup(x, 'html.parser').get_text().strip()\n",
    "    x = x.replace(' br ',' ')\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85d00ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_cleaned = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9adaa995",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_cleaned = posts_cleaned[['text','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e7ffa615",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_cleaned['text'] = posts_cleaned['text'].apply(lambda x: clean_post(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e28cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24235f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5e6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97752462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd6f0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = corpus[i].lower()\n",
    "    corpus[i] = re.sub(r'\\W+',' ',corpus[i]) # Replace everything non-alpahnumeric by ' '\n",
    "    corpus[i] = re.sub(r'\\s+',' ',corpus[i]) # Replace one or more whitespaces by  ' '\n",
    "    corpus[i] = re.sub(r'\\d+',' ',corpus[i]) # Replace one or more digits by  ' '\n",
    "    corpus[i] = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\" \", corpus[i]) # Replace e-mails by ' '\n",
    "    # Replace urls by ''\n",
    "    corpus[i] = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', ' ' , corpus[i]) \n",
    "    # Replace html tags by ''\n",
    "    corpus[i] = BeautifulSoup(corpus[i], 'html.parser').get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1301e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = {}\n",
    "for sentence in corpus:\n",
    "    words = sentence.split()\n",
    "    #tokens = nltk.word_tokenize(sentence) # To get the words, it can be also done with sentence.split()\n",
    "    for word in words:\n",
    "        if ( word not in wordfreq.keys() ): ## first time appearnce in the sentence\n",
    "            wordfreq[word] = 1 # We initialize the corresponding counter\n",
    "        else: ## if the world is already existed in the dictionalry \n",
    "            wordfreq[word] += 1 # We increase the corresponding counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51c5e654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 249164,\n",
       " 'know': 15190,\n",
       " 'why': 8066,\n",
       " 'some': 5692,\n",
       " 'people': 10114,\n",
       " 'are': 10008,\n",
       " 'repulsed': 4,\n",
       " 'by': 4215,\n",
       " 'this': 27017,\n",
       " 'sub': 870,\n",
       " 'all': 15546,\n",
       " 'teenagers': 515,\n",
       " 'aliens': 22,\n",
       " 'source': 58,\n",
       " 'icon': 27,\n",
       " 'what': 16047,\n",
       " 'determines': 4,\n",
       " 'if': 15896,\n",
       " 'you': 24932,\n",
       " 'get': 12004,\n",
       " 'a': 62695,\n",
       " 'response': 124,\n",
       " 'am': 12484,\n",
       " 'in': 29268,\n",
       " 'crisis': 199,\n",
       " 'have': 28630,\n",
       " 'been': 9820,\n",
       " 'living': 2817,\n",
       " 'actually': 2241,\n",
       " 'is': 34201,\n",
       " 'it': 56952,\n",
       " 'that': 29564,\n",
       " 'no': 14117,\n",
       " 'one': 9538,\n",
       " 'cares': 1111,\n",
       " 'unless': 255,\n",
       " 'scream': 121,\n",
       " 'm': 45240,\n",
       " 'gonna': 2909,\n",
       " 'effing': 6,\n",
       " 'kill': 7160,\n",
       " 'myself': 15575,\n",
       " 'now': 11041,\n",
       " 'bye': 420,\n",
       " 'lines': 102,\n",
       " 'busy': 179,\n",
       " 'chat': 896,\n",
       " 'forums': 26,\n",
       " 'nobody': 1622,\n",
       " 'hate': 4684,\n",
       " 'needy': 23,\n",
       " 'little': 1442,\n",
       " 'monster': 130,\n",
       " 'than': 3367,\n",
       " 'becoming': 208,\n",
       " 'but': 28674,\n",
       " 'wtf': 359,\n",
       " 'nothing': 5103,\n",
       " 'do': 22447,\n",
       " 'gets': 1238,\n",
       " 'any': 5640,\n",
       " 'kind': 952,\n",
       " 'of': 40072,\n",
       " 'gives': 396,\n",
       " 'shit': 4324,\n",
       " 'going': 8640,\n",
       " 'to': 113114,\n",
       " 'just': 34707,\n",
       " 'let': 2139,\n",
       " 's': 25530,\n",
       " 'fly': 82,\n",
       " 'the': 63133,\n",
       " 'moonfly': 1,\n",
       " 'high': 990,\n",
       " 'will': 10023,\n",
       " 'pretend': 194,\n",
       " 'be': 22643,\n",
       " 'your': 5262,\n",
       " 'father': 391,\n",
       " 'and': 79884,\n",
       " 'say': 3793,\n",
       " 'proud': 227,\n",
       " 'leave': 1717,\n",
       " 'comment': 810,\n",
       " 'for': 27732,\n",
       " 'happen': 1036,\n",
       " 'even': 8058,\n",
       " 'worth': 1250,\n",
       " 'try': 2798,\n",
       " 'life': 14929,\n",
       " 'could': 4195,\n",
       " 'possibly': 191,\n",
       " 'constant': 452,\n",
       " 'uphill': 14,\n",
       " 'battle': 153,\n",
       " 'everyday': 1214,\n",
       " 'can': 23120,\n",
       " 't': 51315,\n",
       " 'think': 8739,\n",
       " 'anything': 5134,\n",
       " 'realistically': 20,\n",
       " 'make': 5105,\n",
       " 'better': 5147,\n",
       " 'trying': 2708,\n",
       " 'or': 13355,\n",
       " 'not': 17042,\n",
       " 'same': 1663,\n",
       " 'amount': 335,\n",
       " 'suffering': 827,\n",
       " 'failingi': 4,\n",
       " 'so': 25451,\n",
       " 'tired': 3929,\n",
       " 'where': 2912,\n",
       " 'seems': 1441,\n",
       " 'like': 19797,\n",
       " 'right': 4441,\n",
       " 'on': 16952,\n",
       " 'my': 61149,\n",
       " 'second': 560,\n",
       " 'marriage': 66,\n",
       " 'she': 5997,\n",
       " 'constantly': 774,\n",
       " 'depressed': 2108,\n",
       " 'with': 17394,\n",
       " 'massive': 106,\n",
       " 'anxiety': 1316,\n",
       " 'work': 2963,\n",
       " 'hard': 2239,\n",
       " 'we': 4432,\n",
       " 'don': 23931,\n",
       " 'lot': 1833,\n",
       " 'there': 7922,\n",
       " 'roof': 80,\n",
       " 'over': 3987,\n",
       " 'our': 915,\n",
       " 'heads': 42,\n",
       " 'two': 1420,\n",
       " 'beautiful': 349,\n",
       " 'children': 211,\n",
       " 'happy': 3396,\n",
       " 'healthy': 189,\n",
       " 'fed': 83,\n",
       " 'shake': 89,\n",
       " 'feeling': 3309,\n",
       " 'failing': 412,\n",
       " 'them': 5552,\n",
       " 'every': 3950,\n",
       " 'day': 6917,\n",
       " 'everything': 4818,\n",
       " 'power': 174,\n",
       " 'everyone': 4631,\n",
       " 'lives': 573,\n",
       " 'easier': 436,\n",
       " 'when': 7775,\n",
       " 'come': 1690,\n",
       " 'home': 1481,\n",
       " 'reminder': 107,\n",
       " 'failings': 4,\n",
       " 'as': 7693,\n",
       " 'man': 978,\n",
       " 'best': 2450,\n",
       " 'friends': 5537,\n",
       " 'hung': 126,\n",
       " 'himself': 339,\n",
       " 'february': 64,\n",
       " 'didn': 2333,\n",
       " 'believe': 925,\n",
       " 'suicide': 6105,\n",
       " 'was': 12172,\n",
       " 'sin': 31,\n",
       " 'd': 3353,\n",
       " 'probably': 1788,\n",
       " 'follow': 252,\n",
       " 'his': 1448,\n",
       " 'footsteps': 6,\n",
       " 've': 12795,\n",
       " 'wasted': 205,\n",
       " 'much': 6677,\n",
       " 'potential': 104,\n",
       " 'wish': 3575,\n",
       " 'wasn': 875,\n",
       " 'piece': 514,\n",
       " 'become': 687,\n",
       " 'first': 2284,\n",
       " 'time': 8399,\n",
       " 'using': 376,\n",
       " 'premiere': 2,\n",
       " 'pro': 75,\n",
       " 'video': 609,\n",
       " 'https': 3195,\n",
       " 'youtu': 1016,\n",
       " 'coxbwlhe': 1,\n",
       " '_sa': 1,\n",
       " 'coxbwlhe_sa': 1,\n",
       " 'amp': 2857,\n",
       " 'x': 1287,\n",
       " 'b': 1689,\n",
       " 'sorry': 2112,\n",
       " 'its': 2929,\n",
       " 'link': 385,\n",
       " 'reddit': 2266,\n",
       " 'wouldn': 1016,\n",
       " 'allow': 93,\n",
       " 'upload': 33,\n",
       " 'file': 42,\n",
       " 'reason': 2600,\n",
       " 'psst': 2,\n",
       " 'hey': 1121,\n",
       " 'kid': 464,\n",
       " 'wanna': 3629,\n",
       " 'buy': 481,\n",
       " 'cursed': 78,\n",
       " 'scrolls': 3,\n",
       " 'cancermy': 1,\n",
       " 'mom': 1768,\n",
       " 'has': 5252,\n",
       " 'cancer': 234,\n",
       " 'pain': 3557,\n",
       " 'watching': 428,\n",
       " 'hwr': 1,\n",
       " 'suffer': 579,\n",
       " 'point': 3474,\n",
       " 'want': 22736,\n",
       " 'never': 6036,\n",
       " 'give': 2965,\n",
       " 'up': 10854,\n",
       " 'bag': 166,\n",
       " 'snowing': 17,\n",
       " 'me': 42913,\n",
       " 'showers': 15,\n",
       " 'musty': 1,\n",
       " 'ass': 638,\n",
       " 'redditors': 74,\n",
       " 'should': 4318,\n",
       " 'go': 7583,\n",
       " 'shower': 214,\n",
       " 'cant': 2279,\n",
       " 'thisi': 92,\n",
       " 'nuts': 47,\n",
       " 'swear': 186,\n",
       " 'horrible': 670,\n",
       " 'kms': 130,\n",
       " 'badly': 398,\n",
       " 'miserable': 626,\n",
       " 'about': 13404,\n",
       " 'talk': 5267,\n",
       " 'anyone': 6530,\n",
       " 'abt': 77,\n",
       " 'bc': 304,\n",
       " 'burden': 657,\n",
       " 'cater': 3,\n",
       " 'their': 2208,\n",
       " 'emotions': 292,\n",
       " 'mine': 542,\n",
       " 'dont': 3771,\n",
       " 'matter': 1478,\n",
       " 'whole': 1033,\n",
       " 'used': 993,\n",
       " 'tossed': 12,\n",
       " 'away': 2511,\n",
       " 'family': 4181,\n",
       " 'virus': 104,\n",
       " 'ruined': 397,\n",
       " 'anymore': 7194,\n",
       " 'again': 3347,\n",
       " 'found': 1252,\n",
       " 'longer': 1235,\n",
       " 'belt': 139,\n",
       " 'therapist': 652,\n",
       " 'doesn': 2603,\n",
       " 'panicking': 38,\n",
       " 'scared': 2300,\n",
       " 'else': 3056,\n",
       " 'does': 2523,\n",
       " 'welli': 8,\n",
       " 'post': 3246,\n",
       " 'here': 6585,\n",
       " 'transgender': 81,\n",
       " 'honestly': 1169,\n",
       " 'strength': 207,\n",
       " 'switch': 101,\n",
       " 'therapists': 114,\n",
       " 'thought': 2702,\n",
       " 'at': 10246,\n",
       " 'face': 753,\n",
       " 'rejection': 49,\n",
       " 'distrust': 1,\n",
       " 'from': 6775,\n",
       " 'someone': 6756,\n",
       " 'who': 6298,\n",
       " 'shared': 31,\n",
       " 'traumas': 14,\n",
       " 'thinks': 363,\n",
       " 'coping': 138,\n",
       " 'mechanism': 30,\n",
       " 'true': 463,\n",
       " 'lost': 1974,\n",
       " 'oh': 709,\n",
       " 'god': 1186,\n",
       " 'would': 8615,\n",
       " 'after': 2942,\n",
       " 'suffered': 98,\n",
       " 'entire': 469,\n",
       " 'being': 5520,\n",
       " 'trapped': 348,\n",
       " 'body': 1106,\n",
       " 'how': 10753,\n",
       " 'help': 7946,\n",
       " 'die': 7584,\n",
       " 'll': 6176,\n",
       " 'hi': 536,\n",
       " 'please': 4644,\n",
       " 'read': 882,\n",
       " 'russia': 18,\n",
       " 'finish': 266,\n",
       " 'school': 3124,\n",
       " 'pass': 364,\n",
       " 'exams': 104,\n",
       " 'awful': 414,\n",
       " 'question': 890,\n",
       " 'maybe': 2361,\n",
       " 'notice': 274,\n",
       " 'fixed': 80,\n",
       " 'already': 1912,\n",
       " 'photo': 46,\n",
       " 'decide': 257,\n",
       " 'comments': 984,\n",
       " 'because': 8568,\n",
       " 'only': 6775,\n",
       " 'picture': 189,\n",
       " 'facemask': 1,\n",
       " 'mind': 1710,\n",
       " 'really': 8905,\n",
       " 'ugly': 661,\n",
       " 'had': 5423,\n",
       " 'gun': 829,\n",
       " 'pull': 283,\n",
       " 'fucking': 6597,\n",
       " 'trigger': 245,\n",
       " 'moment': 689,\n",
       " 'translate': 14,\n",
       " 'message': 469,\n",
       " 'female': 231,\n",
       " 'unga': 8,\n",
       " 'selfish': 644,\n",
       " 'wants': 1344,\n",
       " 'more': 5660,\n",
       " 'loved': 877,\n",
       " 'ones': 576,\n",
       " 're': 3081,\n",
       " 'suicidal': 3593,\n",
       " 'cause': 1097,\n",
       " 'u': 2137,\n",
       " 'still': 4056,\n",
       " 'went': 1051,\n",
       " 'need': 6516,\n",
       " 'coins': 47,\n",
       " 'load': 57,\n",
       " 'weeks': 964,\n",
       " 'keeps': 562,\n",
       " 'showing': 71,\n",
       " 'loading': 22,\n",
       " 'errors': 13,\n",
       " 'knows': 590,\n",
       " 'fix': 434,\n",
       " 'husband': 249,\n",
       " 'off': 3381,\n",
       " 'without': 2103,\n",
       " 'methinking': 1,\n",
       " 'hanging': 496,\n",
       " 'once': 1191,\n",
       " 'nice': 1100,\n",
       " 'guy': 944,\n",
       " 'good': 5360,\n",
       " 'enough': 2687,\n",
       " 'too': 5341,\n",
       " 'many': 2107,\n",
       " 'mental': 1274,\n",
       " 'health': 681,\n",
       " 'problems': 959,\n",
       " 'they': 10024,\n",
       " 'control': 493,\n",
       " 'around': 2386,\n",
       " 'gobasically': 2,\n",
       " 'title': 615,\n",
       " 'says': 884,\n",
       " 'end': 5944,\n",
       " 'close': 1246,\n",
       " 'wuss': 9,\n",
       " 'out': 11134,\n",
       " 'last': 3687,\n",
       " 'other': 3122,\n",
       " 'side': 438,\n",
       " 'reasonsmy': 1,\n",
       " 'sister': 485,\n",
       " 'bitch': 366,\n",
       " 'past': 1521,\n",
       " 'few': 2206,\n",
       " 'days': 2227,\n",
       " 'her': 4683,\n",
       " 'way': 5012,\n",
       " 'which': 1584,\n",
       " 'haven': 1445,\n",
       " 'literally': 1232,\n",
       " 'said': 1922,\n",
       " 'rude': 78,\n",
       " 'whatsoever': 56,\n",
       " 'quiet': 137,\n",
       " 'less': 762,\n",
       " 'engaging': 6,\n",
       " 'conversation': 244,\n",
       " 'feel': 14925,\n",
       " 'shitty': 658,\n",
       " 'physically': 307,\n",
       " 'mentally': 439,\n",
       " 'excited': 185,\n",
       " 'mean': 1190,\n",
       " 'something': 4191,\n",
       " 'short': 490,\n",
       " 'tempered': 5,\n",
       " 'exhausting': 88,\n",
       " 'running': 301,\n",
       " 'patience': 31,\n",
       " 'got': 4491,\n",
       " 'mug': 8,\n",
       " 'pic': 67,\n",
       " 'gromit': 4,\n",
       " 'gift': 76,\n",
       " 'hello': 429,\n",
       " 'hope': 2661,\n",
       " 'well': 2156,\n",
       " 'enjoying': 69,\n",
       " 'ready': 1108,\n",
       " 'escape': 410,\n",
       " 'cursei': 3,\n",
       " 'lived': 229,\n",
       " 'pathetic': 477,\n",
       " 'things': 4111,\n",
       " 'improve': 170,\n",
       " 'always': 3401,\n",
       " 'low': 404,\n",
       " 'value': 136,\n",
       " 'male': 357,\n",
       " 'sick': 1388,\n",
       " 'garbage': 163,\n",
       " 'government': 102,\n",
       " 'won': 2379,\n",
       " 'castrate': 4,\n",
       " 'capable': 64,\n",
       " 'attracting': 2,\n",
       " 'woman': 252,\n",
       " 'through': 3005,\n",
       " 'stuck': 659,\n",
       " 'curse': 51,\n",
       " 'libido': 4,\n",
       " 'years': 4648,\n",
       " 'thanks': 1070,\n",
       " 'parents': 2663,\n",
       " 'under': 381,\n",
       " 'wing': 6,\n",
       " 'quality': 77,\n",
       " 'failure': 725,\n",
       " 'figure': 281,\n",
       " 'cheap': 59,\n",
       " 'efficient': 17,\n",
       " 'minimal': 20,\n",
       " 'since': 2324,\n",
       " 'peacefully': 80,\n",
       " 'via': 61,\n",
       " 'euthanasia': 39,\n",
       " 'im': 7324,\n",
       " 'fuckin': 186,\n",
       " 'sebastian': 5,\n",
       " 'vettel': 1,\n",
       " 'checo': 1,\n",
       " 'podium': 10,\n",
       " 'fuck': 4456,\n",
       " 'discord': 529,\n",
       " 'full': 548,\n",
       " 'holes': 14,\n",
       " 'mocked': 10,\n",
       " 'due': 551,\n",
       " 'mic': 25,\n",
       " 'name': 654,\n",
       " 'colin': 1,\n",
       " 'immediately': 132,\n",
       " 'love': 3833,\n",
       " 'pretty': 1620,\n",
       " 'coming': 782,\n",
       " 'down': 2577,\n",
       " 'filler': 8848,\n",
       " 'contemplatingi': 3,\n",
       " 'sitting': 443,\n",
       " 'an': 6029,\n",
       " 'hour': 544,\n",
       " 'bottle': 332,\n",
       " 'pills': 1188,\n",
       " 'hand': 408,\n",
       " 'sad': 1994,\n",
       " 'redeemable': 3,\n",
       " 'qualities': 26,\n",
       " 'friend': 2924,\n",
       " 'annoying': 323,\n",
       " 'anyway': 814,\n",
       " 'straight': 445,\n",
       " 'boris': 5,\n",
       " 'johnson': 5,\n",
       " 'zaddy': 1,\n",
       " 'agree': 111,\n",
       " 'posting': 985,\n",
       " 'verse': 10,\n",
       " 'until': 1791,\n",
       " 'seee': 1,\n",
       " 'agaaaaaaaaaaaaaaaaaaaaaaaaaaaaaain': 1,\n",
       " 'throw': 285,\n",
       " 'bridge': 332,\n",
       " 'today': 3233,\n",
       " 'decided': 731,\n",
       " 'seem': 853,\n",
       " 'then': 4146,\n",
       " 'brother': 589,\n",
       " 'relaxing': 29,\n",
       " 'listening': 426,\n",
       " 'music': 660,\n",
       " 'rant': 201,\n",
       " 'thoughtsi': 57,\n",
       " 'urge': 280,\n",
       " 'stay': 1202,\n",
       " 'alive': 1944,\n",
       " 'long': 2745,\n",
       " 'keep': 3520,\n",
       " 'image': 110,\n",
       " 'doing': 3012,\n",
       " 'feels': 1769,\n",
       " 'marathon': 4,\n",
       " 'across': 151,\n",
       " 'line': 278,\n",
       " 'death': 2179,\n",
       " 'look': 1709,\n",
       " 'accident': 262,\n",
       " 'planned': 248,\n",
       " 'guess': 1786,\n",
       " 'chest': 318,\n",
       " 'hopefully': 468,\n",
       " 'stop': 3287,\n",
       " 'thinking': 2640,\n",
       " 'comes': 555,\n",
       " 'before': 2994,\n",
       " 'finally': 1877,\n",
       " 'exit': 89,\n",
       " 'job': 2221,\n",
       " 'done': 3279,\n",
       " 'judging': 31,\n",
       " 'based': 157,\n",
       " 'christmas': 433,\n",
       " 'gifts': 29,\n",
       " 'tell': 3185,\n",
       " 'wished': 65,\n",
       " 'received': 72,\n",
       " 'also': 2047,\n",
       " 'gave': 475,\n",
       " 'others': 1022,\n",
       " 'understand': 1104,\n",
       " 'flat': 66,\n",
       " 'earthers': 6,\n",
       " 'doesnt': 299,\n",
       " 'exist': 691,\n",
       " 'stupid': 1256,\n",
       " 'reasonmy': 1,\n",
       " 'somehow': 327,\n",
       " 'started': 1150,\n",
       " 'fine': 623,\n",
       " 'depression': 2430,\n",
       " 'changed': 293,\n",
       " 'makes': 1887,\n",
       " 'year': 3082,\n",
       " 'stopped': 559,\n",
       " 'results': 91,\n",
       " 'near': 266,\n",
       " 'thing': 3217,\n",
       " 'see': 4477,\n",
       " 'eyes': 405,\n",
       " 'bed': 983,\n",
       " 'miss': 806,\n",
       " 'ngl': 155,\n",
       " 'missed': 189,\n",
       " 'distance': 86,\n",
       " 'maturity': 2,\n",
       " 'made': 2460,\n",
       " 'us': 1224,\n",
       " 'change': 1112,\n",
       " 'gone': 1683,\n",
       " 'nana': 9,\n",
       " 'dad': 1146,\n",
       " 'arrested': 32,\n",
       " 'crime': 57,\n",
       " 'he': 5102,\n",
       " 'committed': 222,\n",
       " 'girlfriend': 1298,\n",
       " 'remember': 907,\n",
       " 'fighting': 435,\n",
       " 'most': 1985,\n",
       " 'affect': 103,\n",
       " 'safe': 313,\n",
       " 'university': 233,\n",
       " 'worse': 2211,\n",
       " 'motivation': 397,\n",
       " 'live': 5023,\n",
       " 'waking': 304,\n",
       " 'gifted': 18,\n",
       " 'opportunity': 136,\n",
       " 'socially': 126,\n",
       " 'competent': 6,\n",
       " 'girls': 848,\n",
       " 'week': 1431,\n",
       " 'such': 1140,\n",
       " 'coward': 345,\n",
       " 'blew': 28,\n",
       " 'iti': 333,\n",
       " 'ever': 3822,\n",
       " 'invited': 42,\n",
       " 'beach': 54,\n",
       " 'trip': 139,\n",
       " 'guys': 2843,\n",
       " 'left': 2051,\n",
       " 'demanded': 4,\n",
       " 'nervous': 134,\n",
       " 'smoke': 115,\n",
       " 'forever': 622,\n",
       " 'relationship': 811,\n",
       " 'bf': 233,\n",
       " 'broke': 687,\n",
       " 'almost': 1466,\n",
       " 'month': 847,\n",
       " 'him': 2584,\n",
       " 'text': 747,\n",
       " 'burdenmy': 1,\n",
       " 'supported': 30,\n",
       " 'four': 191,\n",
       " 'works': 397,\n",
       " 'while': 1961,\n",
       " 'blunder': 1,\n",
       " 'stays': 42,\n",
       " 'homework': 215,\n",
       " 'own': 1557,\n",
       " 'bother': 347,\n",
       " 'hurting': 551,\n",
       " 'herself': 300,\n",
       " 'staying': 265,\n",
       " 'did': 2775,\n",
       " 'met': 303,\n",
       " 'hurt': 2004,\n",
       " 'completely': 788,\n",
       " 'dependent': 36,\n",
       " 'happiness': 550,\n",
       " 'goals': 125,\n",
       " 'discipline': 11,\n",
       " 'person': 2913,\n",
       " 'soon': 1481,\n",
       " 'grow': 198,\n",
       " 'old': 1802,\n",
       " 'alone': 3012,\n",
       " 'committing': 240,\n",
       " 'loseri': 7,\n",
       " 'virgin': 171,\n",
       " 'small': 423,\n",
       " 'penis': 176,\n",
       " 'themselves': 542,\n",
       " 'fact': 786,\n",
       " 'aren': 518,\n",
       " 'wanted': 1921,\n",
       " 'world': 2740,\n",
       " 'killed': 707,\n",
       " 'instantly': 85,\n",
       " 'joke': 548,\n",
       " 'ensure': 29,\n",
       " 'dead': 1795,\n",
       " 'pm': 561,\n",
       " 'super': 437,\n",
       " 'bored': 1579,\n",
       " 'taking': 993,\n",
       " 'break': 631,\n",
       " 'videogames': 23,\n",
       " 'cuz': 323,\n",
       " 'back': 3639,\n",
       " 'yay': 125,\n",
       " 'self': 1789,\n",
       " 'harm': 520,\n",
       " 'attempt': 873,\n",
       " 'oding': 26,\n",
       " 'crap': 182,\n",
       " 'majority': 56,\n",
       " 'able': 1346,\n",
       " 'handle': 587,\n",
       " 'stress': 384,\n",
       " 'properly': 157,\n",
       " 'driving': 230,\n",
       " 'picking': 31,\n",
       " 'phone': 632,\n",
       " 'disappearing': 23,\n",
       " 'jumping': 311,\n",
       " 'cliff': 69,\n",
       " 'door': 206,\n",
       " 'hang': 809,\n",
       " 'idk': 1702,\n",
       " 'freak': 127,\n",
       " 'hospital': 958,\n",
       " 'jewish': 7,\n",
       " 'pride': 36,\n",
       " 'asking': 588,\n",
       " 'googling': 27,\n",
       " 'failed': 904,\n",
       " 'uni': 103,\n",
       " 'myselfi': 383,\n",
       " 'means': 534,\n",
       " 'take': 3981,\n",
       " 'total': 135,\n",
       " 'december': 109,\n",
       " 'resit': 3,\n",
       " 'extremely': 420,\n",
       " 'disapointed': 5,\n",
       " 'expectations': 69,\n",
       " 'cannot': 667,\n",
       " 'understanding': 90,\n",
       " 'expect': 246,\n",
       " 'killing': 1833,\n",
       " 'wwhat': 1,\n",
       " 'fail': 601,\n",
       " 'personi': 19,\n",
       " 'fucked': 1056,\n",
       " 'head': 1567,\n",
       " 'deserve': 1143,\n",
       " 'painful': 539,\n",
       " 'bad': 3468,\n",
       " 'cum': 133,\n",
       " 'gods': 39,\n",
       " 'dum': 15,\n",
       " 'finished': 226,\n",
       " 'normal': 794,\n",
       " 'y': 1146,\n",
       " 'very': 2567,\n",
       " 'game': 722,\n",
       " 'liked': 197,\n",
       " 'pandemic': 93,\n",
       " 'giving': 609,\n",
       " 'dark': 425,\n",
       " 'recently': 840,\n",
       " 'became': 160,\n",
       " 'lawyer': 23,\n",
       " 'came': 684,\n",
       " 'unemployed': 109,\n",
       " 'whose': 52,\n",
       " 'isn': 1612,\n",
       " 'house': 903,\n",
       " 'pressuring': 8,\n",
       " 'find': 2701,\n",
       " 'easy': 654,\n",
       " 'especially': 372,\n",
       " 'economy': 18,\n",
       " 'hoping': 404,\n",
       " 'married': 174,\n",
       " 'survive': 303,\n",
       " 'thoughts': 2755,\n",
       " 'sucks': 677,\n",
       " 'felt': 1391,\n",
       " 'worthless': 791,\n",
       " 'worked': 291,\n",
       " 'happens': 624,\n",
       " 'helpi': 247,\n",
       " 'having': 2313,\n",
       " 'breakdown': 134,\n",
       " 'appreciate': 251,\n",
       " 'legends': 31,\n",
       " 'dies': 96,\n",
       " 'fightingi': 6,\n",
       " 'behind': 456,\n",
       " 'age': 536,\n",
       " 'anxious': 263,\n",
       " 'angry': 514,\n",
       " 'skills': 175,\n",
       " 'exhausted': 309,\n",
       " 'wrong': 1478,\n",
       " 'cry': 911,\n",
       " 'sleep': 2268,\n",
       " 'numb': 395,\n",
       " 'tried': 2920,\n",
       " 'rely': 52,\n",
       " 'cope': 327,\n",
       " 'disappoint': 90,\n",
       " 'tiredi': 114,\n",
       " 'inf': 5,\n",
       " 'n': 462,\n",
       " 'tymagic': 5,\n",
       " 'birthday': 1194,\n",
       " 'tag': 41,\n",
       " 'struggle': 287,\n",
       " 'though': 1327,\n",
       " 'entitled': 25,\n",
       " 'accepted': 161,\n",
       " 'asked': 668,\n",
       " 'attract': 17,\n",
       " 'men': 233,\n",
       " 'attracts': 2,\n",
       " 'ayo': 41,\n",
       " 'megathiccc': 54,\n",
       " 'gotchu': 5,\n",
       " 'another': 1670,\n",
       " 'award': 557,\n",
       " 'bro': 363,\n",
       " 'peep': 13,\n",
       " 'flair': 129,\n",
       " 'couple': 653,\n",
       " 'alonei': 70,\n",
       " 'single': 860,\n",
       " 'cared': 298,\n",
       " 'place': 1418,\n",
       " 'irrelevant': 18,\n",
       " 'join': 551,\n",
       " 'groups': 53,\n",
       " 'clubs': 11,\n",
       " 'chatrooms': 2,\n",
       " 'fit': 205,\n",
       " 'rest': 605,\n",
       " 'reading': 505,\n",
       " 'helps': 321,\n",
       " 'clich√©i': 1,\n",
       " 'new': 1758,\n",
       " 'experience': 451,\n",
       " 'nother': 3,\n",
       " 'earth': 355,\n",
       " 'uncomfortable': 124,\n",
       " 'sparks': 4,\n",
       " 'sober': 122,\n",
       " 'months': 1639,\n",
       " 'planning': 496,\n",
       " 'drink': 488,\n",
       " 'tomorrow': 1289,\n",
       " 'yayy': 9,\n",
       " 'throwaway': 121,\n",
       " 'account': 533,\n",
       " 'main': 184,\n",
       " 'existing': 308,\n",
       " 'night': 1889,\n",
       " 'putting': 312,\n",
       " 'bullet': 149,\n",
       " 'event': 83,\n",
       " 'city': 157,\n",
       " 'spending': 107,\n",
       " 'talentless': 14,\n",
       " 'mediocre': 37,\n",
       " 'unlikeable': 8,\n",
       " 'liar': 41,\n",
       " 'desperate': 194,\n",
       " 'attention': 587,\n",
       " 'lmao': 437,\n",
       " 'againgonna': 1,\n",
       " 'exactly': 273,\n",
       " 'put': 1642,\n",
       " 'longest': 61,\n",
       " 'charger': 17,\n",
       " 'upset': 332,\n",
       " 'helped': 392,\n",
       " 'far': 774,\n",
       " 'playing': 416,\n",
       " 'games': 511,\n",
       " 'manga': 23,\n",
       " 'telling': 804,\n",
       " 'members': 131,\n",
       " 'favorite': 419,\n",
       " 'yeah': 944,\n",
       " 'answer': 579,\n",
       " 'winning': 57,\n",
       " 'talking': 1119,\n",
       " 'might': 1842,\n",
       " 'saying': 984,\n",
       " 'goodbye': 941,\n",
       " 'seemed': 118,\n",
       " 'unstable': 76,\n",
       " 'smiled': 27,\n",
       " 'glad': 169,\n",
       " 'caught': 150,\n",
       " 'worry': 412,\n",
       " 'contacted': 29,\n",
       " 'prevention': 93,\n",
       " 'department': 18,\n",
       " 'deal': 1033,\n",
       " 'drugs': 484,\n",
       " 'anorexia': 28,\n",
       " 'sort': 343,\n",
       " 'stuff': 1081,\n",
       " 'told': 2017,\n",
       " 'psychologist': 91,\n",
       " 'trajectory': 3,\n",
       " 'failurewhy': 1,\n",
       " 'shouldn': 524,\n",
       " 'agender': 1,\n",
       " 'girl': 2030,\n",
       " 'edit': 400,\n",
       " 'happening': 357,\n",
       " 'worst': 719,\n",
       " 'iton': 1,\n",
       " 'mg': 472,\n",
       " 'lexapro': 26,\n",
       " 'plus': 160,\n",
       " 'mirtazapine': 9,\n",
       " 'rd': 115,\n",
       " 'engineering': 30,\n",
       " 'broken': 514,\n",
       " 'half': 551,\n",
       " 'scan': 5,\n",
       " 'brain': 731,\n",
       " 'tumor': 19,\n",
       " 'use': 996,\n",
       " 'lemon': 19,\n",
       " 'juice': 53,\n",
       " 'lube': 5,\n",
       " 'yes': 755,\n",
       " 'thatyesterday': 1,\n",
       " 'cousin': 96,\n",
       " 'nose': 85,\n",
       " 'football': 49,\n",
       " 'intended': 28,\n",
       " 'anyeone': 1,\n",
       " 'call': 1131,\n",
       " 'snapchat': 73,\n",
       " 'human': 669,\n",
       " 'contact': 245,\n",
       " 'uhhhhhhhhmmmm': 1,\n",
       " 'uhhhhh': 8,\n",
       " 'ummmmmmm': 1,\n",
       " 'uhhhhhmmmmmm': 1,\n",
       " 'hmmmmmmmmm': 1,\n",
       " 'pinot': 2,\n",
       " 'seltzer': 2,\n",
       " 'alprazolam': 5,\n",
       " 'xanax': 115,\n",
       " 'pack': 63,\n",
       " 'oded': 5,\n",
       " 'ago': 1904,\n",
       " 'late': 432,\n",
       " 'next': 1414,\n",
       " 'hours': 1257,\n",
       " 'sure': 2069,\n",
       " 'fast': 301,\n",
       " 'possible': 517,\n",
       " 'drinking': 372,\n",
       " 'curious': 299,\n",
       " 'options': 258,\n",
       " 'free': 1037,\n",
       " 'add': 272,\n",
       " 'painless': 357,\n",
       " 'yourself': 894,\n",
       " 'disappear': 285,\n",
       " 'methods': 205,\n",
       " 'messy': 50,\n",
       " 'looked': 213,\n",
       " 'train': 288,\n",
       " 'suicides': 44,\n",
       " 'seeing': 518,\n",
       " 'bodies': 25,\n",
       " 'cut': 1040,\n",
       " 'guts': 136,\n",
       " 'spilling': 5,\n",
       " 'faces': 36,\n",
       " 'check': 476,\n",
       " 'dignity': 27,\n",
       " 'desecrate': 2,\n",
       " 'strong': 538,\n",
       " 'shoot': 283,\n",
       " 'changes': 130,\n",
       " 'needed': 453,\n",
       " 'definition': 23,\n",
       " 'state': 435,\n",
       " 'virginia': 14,\n",
       " 'getting': 3113,\n",
       " 'terrified': 227,\n",
       " 'mention': 116,\n",
       " 'avid': 4,\n",
       " 'target': 13,\n",
       " 'shooter': 9,\n",
       " 'afraid': 1033,\n",
       " 'admitting': 23,\n",
       " 'may': 914,\n",
       " 'inhibit': 1,\n",
       " 'owning': 6,\n",
       " 'firearm': 32,\n",
       " 'future': 1114,\n",
       " 'general': 192,\n",
       " 'idea': 935,\n",
       " 'thank': 1022,\n",
       " 'sacrifice': 28,\n",
       " 'alright': 224,\n",
       " 'boys': 448,\n",
       " 'needs': 426,\n",
       " 'stick': 161,\n",
       " 'dicks': 32,\n",
       " 'inside': 634,\n",
       " 'computer': 136,\n",
       " 'fan': 98,\n",
       " 'into': 2675,\n",
       " ...}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75bf2b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = list(stopwords.words('english')) \n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6d1fa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'she',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'don',\n",
       " 'should',\n",
       " 'should',\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " 'aren',\n",
       " 'couldn',\n",
       " 'couldn',\n",
       " 'didn',\n",
       " 'didn',\n",
       " 'doesn',\n",
       " 'doesn',\n",
       " 'hadn',\n",
       " 'hadn',\n",
       " 'hasn',\n",
       " 'hasn',\n",
       " 'haven',\n",
       " 'haven',\n",
       " 'isn',\n",
       " 'isn',\n",
       " 'ma',\n",
       " 'mightn',\n",
       " 'mightn',\n",
       " 'mustn',\n",
       " 'mustn',\n",
       " 'needn',\n",
       " 'needn',\n",
       " 'shan',\n",
       " 'shan',\n",
       " 'shouldn',\n",
       " 'shouldn',\n",
       " 'wasn',\n",
       " 'wasn',\n",
       " 'weren',\n",
       " 'weren',\n",
       " 'won',\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'wouldn']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(stop_words)):\n",
    "    stop_words[i] = re.sub(r\"\\s*'\\s*\\w*\",\"\",stop_words[i])\n",
    "\n",
    "#stop_words = [word for word in list(np.unique(stop_words)) if len(word) > 1]\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "664d6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [(wordfreq[key],key) for key in list(wordfreq.keys()) if key not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f421191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 19797),\n",
       " ('know', 15190),\n",
       " ('life', 14929),\n",
       " ('feel', 14925),\n",
       " ('get', 12004),\n",
       " ('people', 10114),\n",
       " ('one', 9538),\n",
       " ('really', 8905),\n",
       " ('filler', 8848),\n",
       " ('think', 8739),\n",
       " ('going', 8640),\n",
       " ('would', 8615),\n",
       " ('time', 8399),\n",
       " ('even', 8058),\n",
       " ('help', 7946),\n",
       " ('die', 7584),\n",
       " ('go', 7583),\n",
       " ('im', 7324),\n",
       " ('anymore', 7194),\n",
       " ('kill', 7160)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.sort(reverse = True)\n",
    "\n",
    "# Here we keep only the 20 most frequent words but it can be changed to another bigger value\n",
    "corpus_freq = [(word[1],word[0]) for word in corpus[:21]] \n",
    "corpus_freq = corpus_freq[1:]\n",
    "corpus_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7fdfa4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/deni.emmer/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('like', 19797),\n",
       " ('know', 15190),\n",
       " ('life', 14929),\n",
       " ('feel', 14925),\n",
       " ('get', 12004),\n",
       " ('people', 10114),\n",
       " ('one', 9538),\n",
       " ('really', 8905),\n",
       " ('filler', 8848),\n",
       " ('think', 8739),\n",
       " ('going', 8640),\n",
       " ('would', 8615),\n",
       " ('time', 8399),\n",
       " ('even', 8058),\n",
       " ('help', 7946),\n",
       " ('die', 7584),\n",
       " ('go', 7583),\n",
       " ('im', 7324),\n",
       " ('anymore', 7194),\n",
       " ('kill', 7160)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "corpus_freq = [(lem.lemmatize(word[0]),word[1]) for word in corpus_freq]\n",
    "corpus_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32fc3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {word[0]: [] for word in corpus_freq}\n",
    "posts = pd.DataFrame(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "29753302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'know',\n",
       " 'life',\n",
       " 'feel',\n",
       " 'get',\n",
       " 'people',\n",
       " 'one',\n",
       " 'really',\n",
       " 'filler',\n",
       " 'think',\n",
       " 'going',\n",
       " 'would',\n",
       " 'time',\n",
       " 'even',\n",
       " 'help',\n",
       " 'die',\n",
       " 'go',\n",
       " 'im',\n",
       " 'anymore',\n",
       " 'kill']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cols.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90a5fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_inpector(sentence, stop_words, words):\n",
    "    \n",
    "    import re\n",
    "\n",
    "    # Decompose the review in words -> tokens\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    # Cleanup the tokens\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "        tokens[i] = re.sub(r'\\W',' ',tokens[i]) # Replace everything non-alpahnumeric by ' '\n",
    "        tokens[i] = re.sub(r'\\s+','',tokens[i]) # Replace one or more whitespaces by  ' '\n",
    "        tokens[i] = re.sub(r'\\d+','',tokens[i]) # Replace one or more digits by  ' '\n",
    "        tokens[i] = lem.lemmatize(tokens[i])\n",
    "        \n",
    "    # Droping tokens which are \"stopwords\" or empty\n",
    "    tokens = [ token for token in tokens if (token not in stop_words and token != '')]\n",
    "\n",
    "    # Initializing an empty dictionary of word frequencies for the corresponding post\n",
    "    col_freq = {col:0 for col in words}\n",
    "    \n",
    "    # Filling the dictionary with word frequencies in the post\n",
    "    for token in tokens:\n",
    "        if token in words:\n",
    "            col_freq[token] += 1\n",
    "\n",
    "    return col_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5da9d465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'like': 0,\n",
       "  'know': 1,\n",
       "  'life': 0,\n",
       "  'feel': 0,\n",
       "  'get': 0,\n",
       "  'people': 1,\n",
       "  'one': 0,\n",
       "  'really': 0,\n",
       "  'filler': 0,\n",
       "  'think': 0,\n",
       "  'going': 0,\n",
       "  'would': 0,\n",
       "  'time': 0,\n",
       "  'even': 0,\n",
       "  'help': 0,\n",
       "  'die': 0,\n",
       "  'go': 0,\n",
       "  'im': 0,\n",
       "  'anymore': 0,\n",
       "  'kill': 0},\n",
       " {'like': 0,\n",
       "  'know': 0,\n",
       "  'life': 0,\n",
       "  'feel': 0,\n",
       "  'get': 2,\n",
       "  'people': 0,\n",
       "  'one': 1,\n",
       "  'really': 0,\n",
       "  'filler': 0,\n",
       "  'think': 0,\n",
       "  'going': 1,\n",
       "  'would': 0,\n",
       "  'time': 0,\n",
       "  'even': 0,\n",
       "  'help': 0,\n",
       "  'die': 0,\n",
       "  'go': 0,\n",
       "  'im': 0,\n",
       "  'anymore': 0,\n",
       "  'kill': 2}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = list( map(post_inpector, data['text'], \n",
    "                    [stop_words]*data.shape[0], [list(cols.keys())]*data.shape[0] ) )\n",
    "\n",
    "my_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "78f88a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.DataFrame(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd4552f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['class'] = data['class'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e0e1563f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "70291    0\n",
       "70292    0\n",
       "70293    1\n",
       "70294    1\n",
       "70295    0\n",
       "Name: class, Length: 70296, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=data['class'].reset_index(drop=True)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ed0e833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['class'] = posts['class'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ecf005fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = posts.drop(columns='class')\n",
    "y = posts['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test  = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns =['class'])\n",
    "y_test  = pd.DataFrame(y_test, columns =['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d004c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train_res = pd.DataFrame(X_train_res, columns= X_train.columns)\n",
    "y_train_res = pd.DataFrame(y_train_res, columns =['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "29994e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes(df, rating, post ): # rating = stars, review = X; P(R|X)\n",
    "    '''\n",
    "    This function will take a dataframe and it will return the most likely rating for\n",
    "    a given review according to the Bayes Theorem\n",
    "    '''\n",
    "    df2 = df.copy()\n",
    "    p_rating = len(df2[df2['class'] == rating]) / len(df2)\n",
    "    m = ((df2.iloc[:,:-1] == post).apply(sum, axis=1)).tolist()\n",
    "    t = [index for index, value in enumerate(m) if value == 20]\n",
    "    p_post = len(t) / len(df2)\n",
    "    temp = df2[df2['class'] == rating]\n",
    "    m = ((df2[df2['class'] == rating].iloc[:,:-1] == post).apply(sum, axis=1)).tolist()\n",
    "    t = [index for index, value in enumerate(m) if value == 20]\n",
    "    p_rating_post = len(t) / len(temp)\n",
    "    p = ( p_rating * p_rating_post ) / p_post\n",
    "    return round(p,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bfe519cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Probability detection = 0', 0.71), ('Probability detection = 1', 0.29)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a list comprehension to compute the probability of a given review to have\n",
    "# a given rating\n",
    "prob = [bayes(posts, i, posts.iloc[0,:-1].tolist()) for i in ['0','1']]\n",
    "# Normalizing the probabilities\n",
    "partition = np.sum(prob)\n",
    "#partition\n",
    "prob = [ ('Probability detection = ' + str(index),round(p/partition,2)) for index, p in enumerate(prob) ]\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779afc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "nb = CategoricalNB()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "nb.fit(X_train_res, y_train_res['class'])\n",
    "rf.fit(X_train_res, y_train_res['class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
